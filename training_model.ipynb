{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
      "\u001b[1m11490434/11490434\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 0us/step\n",
      "Accuracy del modelo de Random Forest: 0.9692\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from tensorflow.keras.datasets import mnist\n",
    "\n",
    "# Cargar el dataset MNIST directamente desde TensorFlow\n",
    "(X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
    "\n",
    "# Redimensionar y normalizar los datos para el modelo de machine learning\n",
    "X_train = X_train.reshape(X_train.shape[0], -1) / 255.0\n",
    "X_test = X_test.reshape(X_test.shape[0], -1) / 255.0\n",
    "\n",
    "# Entrenar el modelo con Random Forest\n",
    "rf_model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "rf_model.fit(X_train, y_train)\n",
    "\n",
    "# Hacer predicciones\n",
    "y_pred = rf_model.predict(X_test)\n",
    "\n",
    "# Evaluar la precisión del modelo\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Accuracy del modelo de Random Forest: {accuracy:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['random_forest_mnist_model.joblib']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import joblib\n",
    "\n",
    "# Guardar el modelo entrenado en un archivo .joblib\n",
    "joblib.dump(rf_model, 'random_forest_mnist_model.joblib')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cargar el modelo desde el archivo .joblib\n",
    "rf_model = joblib.load('random_forest_mnist_model.joblib')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "El modelo predice que la imagen es un: 7\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import joblib\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Cargar el modelo entrenado desde el archivo .joblib\n",
    "model = joblib.load('random_forest_mnist_model.joblib')\n",
    "\n",
    "# Función para preprocesar la imagen\n",
    "def preprocess_image(img_path):\n",
    "    # Cargar la imagen en escala de grises\n",
    "    img = cv2.imread(img_path, cv2.IMREAD_GRAYSCALE)\n",
    "    \n",
    "    # Verificar si la imagen fue cargada correctamente\n",
    "    if img is None:\n",
    "        raise ValueError(f\"No se pudo cargar la imagen desde la ruta: {img_path}\")\n",
    "    \n",
    "    # Redimensionar la imagen a 28x28 píxeles\n",
    "    img_resized = cv2.resize(img, (28, 28), interpolation=cv2.INTER_AREA)\n",
    "    \n",
    "    # Invertir los colores si la imagen es negra sobre fondo blanco (opcional)\n",
    "    img_resized = 255 - img_resized\n",
    "    \n",
    "    # Mostrar la imagen preprocesada\n",
    "    plt.imshow(img_resized, cmap='gray')\n",
    "    plt.show()\n",
    "    \n",
    "    # Aplanar la imagen a un array 1D y normalizarla\n",
    "    img_resized = img_resized.flatten().astype('float32') / 255.0\n",
    "    \n",
    "    # Redimensionar a la forma esperada por el modelo (1, 784)\n",
    "    img_resized = np.expand_dims(img_resized, axis=0)\n",
    "    \n",
    "    return img_resized\n",
    "\n",
    "# Ruta de la imagen que deseas probar (reemplaza con la ruta de tu imagen)\n",
    "img_path = 'image.png'\n",
    "\n",
    "# Preprocesar la imagen\n",
    "img_preprocessed = preprocess_image(img_path)\n",
    "\n",
    "# Hacer la predicción\n",
    "prediction = model.predict(img_preprocessed)\n",
    "\n",
    "# Mostrar la predicción\n",
    "print(f\"El modelo predice que la imagen es un: {prediction[0]}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/luis/Desktop/ANYONE/ModelImporting/ModelEnv/lib/python3.10/site-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 18ms/step - accuracy: 0.8471 - loss: 0.5133 - val_accuracy: 0.9824 - val_loss: 0.0579\n",
      "Epoch 2/5\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 19ms/step - accuracy: 0.9821 - loss: 0.0587 - val_accuracy: 0.9863 - val_loss: 0.0405\n",
      "Epoch 3/5\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 19ms/step - accuracy: 0.9882 - loss: 0.0380 - val_accuracy: 0.9856 - val_loss: 0.0452\n",
      "Epoch 4/5\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 19ms/step - accuracy: 0.9912 - loss: 0.0277 - val_accuracy: 0.9851 - val_loss: 0.0473\n",
      "Epoch 5/5\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 20ms/step - accuracy: 0.9920 - loss: 0.0245 - val_accuracy: 0.9905 - val_loss: 0.0331\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9866 - loss: 0.0426\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy del modelo de Deep Learning: 0.9905\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Flatten, Conv2D, MaxPooling2D\n",
    "from tensorflow.keras.datasets import mnist\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "# Cargar el dataset MNIST directamente desde TensorFlow\n",
    "(X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
    "\n",
    "# Preprocesar los datos para el modelo de deep learning\n",
    "X_train = X_train.reshape(-1, 28, 28, 1).astype('float32') / 255\n",
    "X_test = X_test.reshape(-1, 28, 28, 1).astype('float32') / 255\n",
    "y_train = to_categorical(y_train, 10)\n",
    "y_test = to_categorical(y_test, 10)\n",
    "\n",
    "# Crear el modelo de deep learning\n",
    "model = Sequential([\n",
    "    Conv2D(32, kernel_size=(3, 3), activation='relu', input_shape=(28, 28, 1)),\n",
    "    MaxPooling2D(pool_size=(2, 2)),\n",
    "    Conv2D(64, kernel_size=(3, 3), activation='relu'),\n",
    "    MaxPooling2D(pool_size=(2, 2)),\n",
    "    Flatten(),\n",
    "    Dense(128, activation='relu'),\n",
    "    Dense(10, activation='softmax')\n",
    "])\n",
    "\n",
    "# Compilar el modelo\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Entrenar el modelo\n",
    "model.fit(X_train, y_train, epochs=5, batch_size=128, validation_data=(X_test, y_test))\n",
    "\n",
    "# Evaluar el modelo\n",
    "test_loss, test_acc = model.evaluate(X_test, y_test)\n",
    "print(f\"Accuracy del modelo de Deep Learning: {test_acc:.4f}\")\n",
    "\n",
    "# Guardar el modelo\n",
    "model.save('deep_learning_mnist_model.h5')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ModelEnv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
